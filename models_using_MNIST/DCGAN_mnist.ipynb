{"cells":[{"cell_type":"markdown","metadata":{},"source":["To generate GIF"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":17239,"status":"ok","timestamp":1634041565770,"user":{"displayName":"Lorenzo Valente","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTh0enxhVzBGrVgHIc03P7l-WgzoGzF2_H_aZg=s64","userId":"09158965273549322331"},"user_tz":-120},"id":"vDD9Q8Eodzlz"},"outputs":[],"source":["!pip install -q git+https://github.com/tensorflow/docs \n","!pip install imageio"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":38,"status":"ok","timestamp":1634041565772,"user":{"displayName":"Lorenzo Valente","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTh0enxhVzBGrVgHIc03P7l-WgzoGzF2_H_aZg=s64","userId":"09158965273549322331"},"user_tz":-120},"id":"3HYjFWp2EZ-o","outputId":"1b9e5cb7-4a38-4c29-bb6e-d02021180afa"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow.python.keras import Input, Sequential\n","from tensorflow.python.keras.engine.functional import Functional\n","from tensorflow.python.keras.engine.keras_tensor import KerasTensor\n","from tensorflow.python.keras.models import Model\n","\n","gpus = tf.config.experimental.list_physical_devices('GPU')\n","if gpus:\n","    try:\n","        # Currently, memory growth needs to be the same across GPUs\n","        for gpu in gpus:\n","            tf.config.experimental.set_memory_growth(gpu, True)\n","        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n","        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n","    except RuntimeError as e:\n","        # Memory growth must be set before GPUs have been initialized\n","        print(e)\n","\n","from tensorflow.keras.layers import (Dense, Lambda, Conv2D, Conv2DTranspose, LeakyReLU, \n","                                    BatchNormalization,ZeroPadding2D, Activation ,Flatten, Reshape, Cropping2D, Dropout)\n","from tensorflow.python.keras.utils.np_utils import to_categorical\n","from tensorflow.keras import backend as K\n","\n","import glob\n","import imageio\n","import os\n","import PIL\n","import time\n","\n","from IPython import display\n","from tensorflow.keras.optimizers import Adam, RMSprop\n","\n","import tensorflow_docs.vis.embed as embed"]},{"cell_type":"markdown","metadata":{},"source":["## Import the MNIST data class and call it."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1185,"status":"ok","timestamp":1634041573950,"user":{"displayName":"Lorenzo Valente","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTh0enxhVzBGrVgHIc03P7l-WgzoGzF2_H_aZg=s64","userId":"09158965273549322331"},"user_tz":-120},"id":"r8AkzCKKVpZd","outputId":"9e24332e-1d34-43f9-f22c-8940ba0e0062"},"outputs":[],"source":["import MNIST_dataset as mnist\n","data = mnist.MNISTData(gan=True)"]},{"cell_type":"markdown","metadata":{},"source":["## Deep Convolutional Generative Adversarial Network with TensorFlow\n","\n","The aim of this exercise is to implement a DCGAN architecture and to test it on the MNIST dataset.\n","\n","Code partially adapted from [TensorFlow Documentation](https://www.tensorflow.org/tutorials/generative/dcgan)."]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":753,"status":"ok","timestamp":1634042366247,"user":{"displayName":"Lorenzo Valente","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTh0enxhVzBGrVgHIc03P7l-WgzoGzF2_H_aZg=s64","userId":"09158965273549322331"},"user_tz":-120},"id":"dn-3dHC4zfW0"},"outputs":[],"source":["class DCGAN():\n","    \"\"\"Deep Convolutional Generative Adversarial Network\"\"\"\n","    \n","    batch_size = 256\n","\n","    def __init__(self, data: mnist.MNISTData):\n","\n","        self.x_train = data.x_train\n","        self.buffer_size = self.x_train.shape[0]\n","\n","        #Preparing dataset\n","        self.train_dataset = tf.data.Dataset.from_tensor_slices(self.x_train)\n","        self.train_dataset = self.train_dataset.shuffle(self.buffer_size).batch(self.batch_size)\n","        \n","        self.latent_dim = 100\n","\n","        self.generator = None\n","        self.g_optimizer = None        \n","        self.discriminator = None\n","        self.d_optimizer = None\n","\n","        # Instantiate a loss function, i.e. function to compute the cross entropy loss\n","        self.loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n","        \n","        self.loss_record = np.array([None, None])\n","        \n","    def make_generator_model(self, optimizer = Adam(learning_rate=1e-4)):\n","        \"\"\"Building the generator.\"\"\"\n","\n","        self.g_optimizer = optimizer\n","        self.generator = Sequential(\n","            [\n","                Input(shape=(self.latent_dim,)),\n","                # We want to generate 100 coefficients to reshape into a 7x7x256 map\n","                Dense(7 * 7 * 256, use_bias=False),\n","                BatchNormalization(momentum=0.8),\n","                LeakyReLU(alpha=0.2),\n","                Reshape((7, 7, 256)),\n","\n","                Conv2DTranspose(128, kernel_size=5, padding='same', use_bias=False),\n","                BatchNormalization(momentum=0.8),\n","                LeakyReLU(alpha=0.2),\n","        \n","                Conv2DTranspose(64, kernel_size=5, strides=(2, 2), padding='same', use_bias=False),\n","                BatchNormalization(momentum=0.8),\n","                LeakyReLU(alpha=0.2),\n","\n","                Conv2DTranspose(1, kernel_size=5, strides=(2, 2), padding='same', use_bias=False),\n","                Activation(\"tanh\"),\n","            ],\n","            name=\"generator\",\n","        )\n","        #assert self.generator.output_shape == (None, 28, 28, 1)\n","\n","    def make_discriminator_model(self, optimizer = Adam(learning_rate=5e-5)):\n","        \"\"\"Building the discriminator.\"\"\"\n","\n","        self.d_optimizer = optimizer\n","        self.discriminator = Sequential(\n","            [\n","                Input(shape=(28, 28, 1)),\n","                Conv2D(64, kernel_size=5, strides=(2, 2), padding='same'),\n","                LeakyReLU(alpha=0.2),\n","                Dropout(0.25),\n","\n","                Conv2D(128, kernel_size=5, strides=(2, 2), padding='same'),\n","                LeakyReLU(alpha=0.2),\n","                Dropout(0.25),\n","\n","                Flatten(),\n","                Dense(1),\n","                Activation('sigmoid'),\n","            ],\n","            name=\"discriminator\"\n","        )\n","                   \n","    def discriminator_loss(self, real_output, fake_output):\n","        real_loss = self.loss_fn(tf.ones_like(real_output), real_output)\n","        fake_loss = self.loss_fn(tf.zeros_like(fake_output), fake_output)\n","        total_loss = real_loss + fake_loss\n","        return total_loss\n","    \n","    def generator_loss(self, fake_output):\n","        return self.loss_fn(tf.ones_like(fake_output), fake_output)\n","\n","    def train_dcgan(self, epochs=100, save_interval = 10):\n","        \"\"\"Training loop.\"\"\"\n","        seed = tf.random.normal([16, self.latent_dim])\n","        start_loop = time.time()\n","        for epoch in range(epochs):\n","            start_epoch = time.time()\n","\n","            for image_batch in self.train_dataset:\n","                gen_loss, disc_loss = self.train_step(tf.cast(image_batch,float))\n","\n","            print('Time for epoch {} is {} sec'.format(epoch + 1, time.time() - start_epoch))\n","            print('Generation loss: {} Discriminator loss: {} '.format(gen_loss, disc_loss))\n","            self.loss_record = np.vstack([self.loss_record, np.array([gen_loss, disc_loss])])\n","        \n","            # If at save interval, than save and disply the generated image samples\n","            if epoch % save_interval == 0:\n","                self.generate_and_save_images(epoch + 1, seed)\n","\n","        print(\"\\nTotal time taken: %.2fs\" % (time.time() - start_loop))\n","        print(\"\\n\\n\\n\")\n","\n","    # The function to be \"compiled\".\n","    @tf.function\n","    def train_step(self, images):\n","        \"\"\"GAN training step.\"\"\"\n","        \n","        # Sample normally distributed points in the latent space\n","        random_latent_vec = tf.random.normal([self.batch_size, self.latent_dim])\n","    \n","        with tf.GradientTape() as g_tape, tf.GradientTape() as d_tape:\n","            gen_imgs = self.generator(random_latent_vec, training=True)\n","\n","            real_output = self.discriminator(images, training=True)\n","            fake_output = self.discriminator(gen_imgs, training=True)\n","\n","            g_loss = self.generator_loss(fake_output)\n","            d_loss = self.discriminator_loss(real_output, fake_output)\n","\n","        gradients_of_generator = g_tape.gradient(g_loss, self.generator.trainable_variables)\n","        gradients_of_discriminator = d_tape.gradient(d_loss, self.discriminator.trainable_variables)\n","\n","        self.g_optimizer.apply_gradients(zip(gradients_of_generator, self.generator.trainable_variables))\n","        self.d_optimizer.apply_gradients(zip(gradients_of_discriminator, self.discriminator.trainable_variables))\n","        \n","        return g_loss, d_loss\n","    \n","    def generate_and_save_images(self, epoch, test_input, save=True):\n","\n","        pred = self.generator(test_input, training=False)\n","\n","        fig = plt.figure(figsize=(5, 5))\n","\n","        for i in range(pred.shape[0]):\n","            plt.subplot(5, 5, i+1)\n","            plt.imshow(pred[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n","            plt.axis('off')\n","        if save:\n","            plt.savefig('./images/GAN/training_checkpoints/image_at_epoch_{:04d}.png'.format(epoch))\n","        plt.show()\n","\n","    def gif(self):\n","        \"\"\"Creation of the gif with generated images over epochs.\"\"\"\n","\n","        with imageio.get_writer('./images/GAN/dcgan.gif', mode='I') as writer:\n","            filenames = glob.glob('./images/GAN/training_checkpoints/image*.png')\n","            filenames = sorted(filenames)\n","            for filename in filenames:\n","                image = imageio.imread(filename)\n","                writer.append_data(image)\n","            image = imageio.imread(filename)\n","            writer.append_data(image)\n","            embed.embed_file('./images/GAN/dcgan.gif')\n","    \n","    def plot_losses(self):\n","        \"\"\"Plotting the Generator and Discriminator losses\"\"\"\n","        plt.plot(self.loss_record[:])\n","        plt.ylabel('Loss')\n","        plt.xlabel('Epoch')\n","        plt.legend(['Generator Loss', 'Discriminator Loss'], loc='best')\n","        plt.title('Generator and Discriminator losses')\n","        plt.savefig('./images/GAN/g_d_losses.png')\n","\n","        plt.show()\n","    \n","    def dir(self):\n","        \"\"\"Creation of the folders path to store the results.\"\"\"\n","        dir = os.path.join(\"images\")\n","        if not os.path.exists(dir):\n","            os.mkdir(dir)\n","        dir2 = os.path.join(\"./images/GAN\")\n","        if not os.path.exists(dir2):\n","            os.mkdir(dir2)\n","        dir3 = os.path.join(\"./images/GAN/training_checkpoints\")\n","        if not os.path.exists(dir3):\n","            os.mkdir(dir3)\n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"xhuln5q4zfW5","outputId":"363d8cd3-bd3d-422e-de86-1f7888f3e395"},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m<ipython-input-5-18d5f27fff1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_discriminator_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_dcgan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_losses\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m<ipython-input-4-698fbeceb4f0>\u001b[0m in \u001b[0;36mtrain_dcgan\u001b[1;34m(self, epochs)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mimage_batch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m                 \u001b[0mgen_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisc_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Time for epoch {} is {} sec'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\miniconda3\\envs\\MLinPhysics\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\miniconda3\\envs\\MLinPhysics\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\miniconda3\\envs\\MLinPhysics\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\miniconda3\\envs\\MLinPhysics\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n","\u001b[1;32m~\\miniconda3\\envs\\MLinPhysics\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n","\u001b[1;32m~\\miniconda3\\envs\\MLinPhysics\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\miniconda3\\envs\\MLinPhysics\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["gan = DCGAN(data)\n","gan.make_generator_model()\n","gan.make_discriminator_model()\n","gan.dir()\n","gan.train_dcgan(epochs=2, save_interval=1)\n","gan.plot_losses()\n","gan.gif()"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"GAN4.ipynb","provenance":[{"file_id":"1nIiHLgYl53OZWhgPmQxm09avXVAOJd5b","timestamp":1633442598877}]},"interpreter":{"hash":"789093bb736187c46b4a361b2c83e244a48ff9bb7ad40e66e5ffb40455c8edff"},"kernelspec":{"display_name":"Python 3.8.8 64-bit ('MLinPhysics': conda)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":0}
