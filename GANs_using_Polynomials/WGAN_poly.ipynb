{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":301,"status":"ok","timestamp":1633441509360,"user":{"displayName":"Lorenzo Valente","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTh0enxhVzBGrVgHIc03P7l-WgzoGzF2_H_aZg=s64","userId":"09158965273549322331"},"user_tz":-120},"id":"3HYjFWp2EZ-o"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow.python.keras import Input, Sequential\n","from tensorflow.python.keras.engine.functional import Functional\n","from tensorflow.python.keras.engine.keras_tensor import KerasTensor\n","from tensorflow.python.keras.models import Model\n","\n","gpus = tf.config.experimental.list_physical_devices('GPU')\n","if gpus:\n","    try:\n","        # Currently, memory growth needs to be the same across GPUs\n","        for gpu in gpus:\n","            tf.config.experimental.set_memory_growth(gpu, True)\n","        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n","        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n","    except RuntimeError as e:\n","        # Memory growth must be set before GPUs have been initialized\n","        print(e)\n","\n","from tensorflow.keras.layers import (Dense, Lambda, Conv2D, Conv2DTranspose, LeakyReLU, \n","                                    BatchNormalization,UpSampling2D, ZeroPadding2D, Activation ,Flatten, Reshape, Cropping2D, Dropout)\n","from tensorflow.python.keras.utils.np_utils import to_categorical\n","from tensorflow.keras.constraints import MinMaxNorm\n","\n","from tensorflow.keras import backend as K\n","\n","import glob\n","import imageio\n","import os\n","import PIL\n","import time\n","\n","from IPython import display\n","from tensorflow.keras.optimizers import Adam, RMSprop\n","\n","import tensorflow_docs.vis.embed as embed"]},{"cell_type":"markdown","metadata":{"id":"JnawiBWUs_5V"},"source":["## Loading the Polynomial dataset"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"data":{"text/plain":["<matplotlib.image.AxesImage at 0x18dc23e31f0>"]},"execution_count":2,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAPsAAAD6CAYAAABnLjEDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAX/UlEQVR4nO2df6hk5XnHv8/MrlESqa7aRXRbbSoNEpotWElo/rCmFisFDQSJpcWCYAoVEhpKtvknSWnAQhP7T0lJyNb9I42KSaoU23SxQhoo/ogxZnWTaqwhu1134xqb3b0/ZubM0z/OWXvvnO9z97xz5syde9/vB4Y789znfc977p1nzsx3nvd5zN0hhNj+9DZ7AUKI+aBgFyITFOxCZIKCXYhMULALkQkKdiEyoVWwm9nNZvZDM3vZzPbNalFCiNlj037PbmZ9AP8F4CYARwA8DeAOd38xGnPprr5ftWfnOtsY/PjMHq11TG0W+NbtY2/uW5DXx3g88Y3WReZg40PfhHOIfJ2uoW6LnjJsXjZnZI+fimSOyJfZ2RoSxlvSsbgrnSPyZU/ohvOunn4Do5Uz9I++g0/RiOsBvOzurwCAmT0A4FYAYbBftWcnnvrmnvWL8yH1XRrX7SvO/grAEvlDrHif+p7x+ikvjd8W+J5XtxHfcDz1rc8JAEtFc9/lYiexcd8zo7p9peD/9hU276huGxT8b7syrM87DHyHxHc05L7FqP6i58RWTlx/nhvxtQF/EerR8fxQzLc3CHzJHP3Il9h7Qx7tk3McfvQ+PinavY2/AsBP1jw+UtmEEAtI5wKdmd1tZs+Y2TM/PVl0fTghRECbYD8KYO178isr2zrc/Yvufp27X3fZJfxtmhCie9p8Zn8awDVmdjXKIP8wgD+YyaoWhD5RRZitRyVCoE/sbDwA9Ikqw8YDQI+oPT2q6gA7evV3U70xf9Fl8+7o1eeNPof3e/Xxo+DNXI/Maz3+OZraybEAwImvM9/gukNloXEgMpJ5vR/4knmDfwONyuDfW5sj0EOjaZvh7iMzuwfAN1H+6fa7+wvTzieE6JY2V3a4+2MAHpvRWoQQHaIMOiEyQcEuRCYo2IXIhFaf2WdBsY3LYqWo5j2m8gd5mlTlj3wbKuwA0Buzbxqajx+N69eOfuDLUmt7gcI+Zqp34EtVemNqPh/uxG6RL1HTgyRPOPlWIkjyBKhvoPL3m8ePruxCZIKCXYhMULALkQkKdiEyYa4CncNRRApGA7raRhOJZuGe5wkicazp+HjehHTZ4GBU+At8d1j9LzywuopkkRhIxLh+j19PRkwMDEQ3dr4erIEKd1Tgo8OBpum24Gm8kS8T2KJQYGm05F9TzTvpyP0AXdmFyAYFuxCZoGAXIhMU7EJkgoJdiEzY9HTZiKKtlN0RVCFPWGpK8YqUecM0XJqy21z1psUriJIOcCE4VO6JvQh8jSjcUQor8+UKfSBb0/FBqioxR+til9X4GwHiGxXbKDaQ3889rRBiO6JgFyITFOxCZEKrz+xm9iqAUyiT20buft0sFiWEmD2zEOh+291fb+o82dZpHFRQbUuxUd7gnIiqwzKYwBamwIb9iKY/VjRvW4Ev8mXCXZQuy3wj4a/x3vVoPK1ky12ZwBaJbkwkjKrpKl1WCNGKtsHuAP7NzL5jZnfPYkFCiG5o+zb+/e5+1Mx+EcBBM/uBu39rrUP1InA3AOy5Qh1hhNgsWl3Z3f1o9fMEgG+g7Ow66aP2T0IsAFMHu5m93cwuPHsfwO8CODSrhQkhZkubt/G7AXzDSvVzB4B/dPd/ncmqElkE5X2eMJU/VsiZ8t7uHVbKtwSRap6isDOBPfRl6a7Ml02KKLWWutLUWA/nbWaLlhar/BOPuRuAdr3eXgHwnmnHCyHmi756EyITFOxCZIKCXYhMmHN12Xp6bLRvnclK3STWtqdtWiwAqqxE1WVTYPvGo2q4TavWpohusXBIxlNPoEf21BeBEMbFvLotbB81br6wpFZRKam1LQQ6pcsKIRTsQuSCgl2ITFCwC5EJCnYhMmFhq8vmRlR1lsEU7qRvBFL6wrGiGglqfiQOpyj3TRX28hfNer2FE9DxkW/dxJT08HAJBTTCSrQJmeK6sguRCQp2ITJBwS5EJijYhciEuQt0hS9eW6dxqH60o21Lp1kQiXGNx3dUXbazve8Nx0dCGhfdmleyZfvpyzmai260rRR3jYU7gq7sQmSCgl2ITFCwC5EJCnYhMuGcAp2Z7Qfw+wBOuPu7K9suAA8CuArAqwBud/efTbOAcSDYMSGvmIG41ZUY1wUp4lpKS6gU0SwFnoE3g5ZOdHxkb5gtl9I+KiFbLyo4yTPognlpu6poDQ39gmknuR/AzRO2fQAed/drADxePRZCLDDnDPaqw8sbE+ZbARyo7h8AcNtslyWEmDXTvqfd7e7HqvuvoawhTzGzu83sGTN75vWTQStKIUTntP4A6+6ODVJF1rZ/ulTtn4TYNKYN9uNmdjkAVD9PzG5JQogumDZd9lEAdwK4t/r5yMxWNAUFyS8ch/mQIoWUFNiuSFLuG64tUvNTWkXx3NzogOxY0Rra+Uac88puZl8F8J8Afs3MjpjZXSiD/CYzewnA71SPhRALzDmv7O5+R/CrD8x4LUKIDtk6GSZCiFYo2IXIhDm3f/Ja+6fcSCkMGc6R0BYqbDfV2Lfd16WRkMaFv2COhHn5Guq2cI96SgXHeWrACcJfhK7sQmSCgl2ITFCwC5EJCnYhMkHBLkQmbHr7p2Le5VZFa6KiGikKeVc0b7OUIP0nLYCbacXYlBZWoXNzdGUXIhMU7EJkgoJdiExQsAuRCZsu0EXkVsAqJa2Vj0+pLhsdS5WEkliAkgkz3c8uhNgeKNiFyAQFuxCZoGAXIhOa1KDbb2YnzOzQGtunzeyomT1X3W7pdplCiLZM2/4JAO5z973V7bHZLkssCj3z2q0rzJzeOlmDBTfq6/y2xZi2/ZMQYovR5jP7PWb2fPU2/+KZrUgI0QnTBvsXALwTwF4AxwB8LnJc2+vt5Mm8688JsZlMFezuftzdC3cfA/gSgOs38H2r19sll0j8F2KzmCr6zvZ5q/gggEORrxBbHjd+WwBSNMNz5sZX7Z9uAHCpmR0B8CkAN5jZXpTdW18F8JF2SxZCdM207Z++3MFahBAdog/RQmSCgl2ITFCwC5EJC1u8QuSHBwr3uAvlexbZrl1lzLLzncGxdGUXIhMU7EJkgoJdiExQsAuRCRLoFoSxt3vd7UTE6nDeuZJyDm2FsGA8TWVNOVbkmzCHruxCZIKCXYhMULALkQkKdiEyQcEuRCZIjc+Q1sp/UIY1SndtCxWyg2N5U3U6Wmtb5T5BNY+KTbBWfI19Nzh/XdmFyAQFuxCZoGAXIhOatH/aY2ZPmNmLZvaCmX20su8ys4Nm9lL1U7XjhVhgmgh0IwAfd/dnzexCAN8xs4MA/hjA4+5+r5ntA7APwCdmtbA+sQ1nNfkmUszgzVTRUmCLaCvcMVL2qI8TUj9DMZDYmWgXCnkdiW50jqiNQss1RDRp/3TM3Z+t7p8CcBjAFQBuBXCgcjsA4LbmhxVCzJukl3IzuwrAbwB4EsBudz9W/eo1ALtnuzQhxCxpHOxm9g4AXwPwMXf/+drfubsjeEOh9k9CLAaNgt3MdqIM9K+4+9cr8/GznWGqnyfYWLV/EmIxaNIRxlA2hTjs7p9f86tHAdwJ4N7q5yPTLKAfZGMNO6vmlxdMdEvZo86FtEB0I//LyJcJbHFWXDPRLfQdswKOkcBXNxkbH9kj36R5m9k2sjOaqPG/BeCPAHzfzJ6rbJ9EGeQPmdldAH4M4PbmhxVCzJsm7Z++DQSXX+ADs12OEKIr9CFaiExQsAuRCQp2ITJhrvvZDYZe7fVl+3733jatNdo3Tn1nsJe8qfIeqvEtfcPUWqJapyj3aamqTGEPfFuq5jPxLSYM2s8uhFCwC5EJCnYhMkHBLkQmqODkDJjJHvWWYly0BprCGhyLp7s2T7elohv15EJakZIuG6Sa0r3rCWmtVIybRVrrpJAW2MJ5A9/ehH2jZ5Gu7EJkgoJdiExQsAuRCQp2ITJBwS5EJsxdje/ber2wF+iHrKhFP9B2qb2j2hetU2ATxkfHSlH/mcIdqd403ZX8H1JSVYtxcA4JKbAsXTYsitFUeU8oSBGq5kVHvqO6rUdspe/EE13pskIIBbsQmaBgFyIT2rR/+rSZHTWz56rbLd0vVwgxLW3aPwHAfe7+N90tb3NJSWHl4+uvpdGcNC019E3ZN87SXYPUWjLHiAhso2A8840FOuJbBOtiYl6ULkuEMDBblNY6YkJaQrps5MtEtygFlviy8QDQm+yJtoFA16Tg5DEAx6r7p8zsbPsnIcQWok37JwC4x8yeN7P96uIqxGLTpv3TFwC8E8BelFf+zwXj3mr/9PrJ4H2LEKJzpm7/5O7H3b1w9zGALwG4no1d2/7p0ktYI2YhxDxoosbT9k9n+7xVfBDAodkvTwgxK9q0f7rDzPai1P9eBfCRDtbXiCj9s/H4BNWd+aakn4bzEoU7Spelqrnzd01MOY/V9PocVDWPFHaaLsv/BmwOprqX9rovVd2BQHknCjtR3QGewhqp5ilprWyOxgo7gP4wSBWf8GU95c7Spv3TY+caK4RYHJRBJ0QmKNiFyAQFuxCZkF112SQxrmGq6Th4zWTpssNASGP2JF8irkV2ltYKAAPmywS+YPyoaH4slho7jtJlR0SgI7bygHU7TYGNBDrqyw/VG6b41m39QeRbV9l6gW9/sN53I4FOV3YhMkHBLkQmKNiFyAQFuxCZoGAXIhMWVo0vSNOuIlAaWZGHSHWnBSWitFRafKJuGzj/M3LVvLlvqHoz3ygFltgHwRpYCuuQKOwDYgOAEVHTo4IUBUlrjXyp8h6muxKFnKjmTEkHeLpr6JuisBN7bxCkwK7WbTtWI98Je1CUA9CVXYhsULALkQkKdiEyQcEuRCbMXaCbFN7GRIgDALaFONIe6B7zhCquQ3DBadAwhbWzFNjAd7Wo/9uYDQBWRjtrtkhgY3MwXybEAVzMG434sQpiHw+jFFiWlsp9m4px4b7zAfENU1XZ+MCXCGxMiAO4GMfGA8CO5fVRYeM4X1ZXdiEyQcEuRCYo2IXIhCYFJ883s6fM7HtV+6fPVParzexJM3vZzB40s/O6X64QYlqaCHSrAG5099NVSelvm9m/APgzlO2fHjCzvwdwF8pa8iEOx3hCZhsG/WqYGDcIssSGxL7idWGqnIMJYVFWGxGsiG11zI/F7KtB9hqzLxf89ZP5rgQCHdujHol5qyxbjghpg1Hw9xqSgpWBQEfFuECgM2JnQhwQCGwk06232j4rjglskZCW4rtjtf7s7y9zeXrHynopu5VA5yWnq4c7q5sDuBHAw5X9AIDbzjWXEGLzaNokol+VkT4B4CCAHwF4093PfoFxBOr/JsRC0yjYq84vewFcibLzy7uaHmBt+6eTJzfI0hdCdEqSGu/ubwJ4AsD7AFxkZmc/vF0J4Ggw5q32T5dcIvFfiM2iiRp/mZldVN2/AMBNAA6jDPoPVW53AnikozUKIWZAEzX+cgAHzKyP8sXhIXf/ZzN7EcADZvZXAL6Lsh/chjiAoa9/Kz8I0mVXSCuh1SB9dIUo5CuBQr7kb6vZzozrtsi+NK4r5OGxiJrOxgPAmVH9WMtFMC9JgV0JfJeZb6Cmrw7Jtw/El6nuADAi9jAFdsCqwAZqPE1hba6mM9+UfedRWmv7FNhAYSfKe3+Z96DqL0+c8AZqfJP2T8+j7Mk+aX8FQedWIcTioQ/RQmSCgl2ITFCwC5EJc93PPnbHmQmBbinoYb5EUkLPBCmwVEgjQlzkGwl0p4vzybqI6BaktZ4umOgWCXRE+AvSWpeYLxHiSjtJ7yVCHMBTY2kKbCDQjZmdCHFA0GYpEt0apsACQL/hfvRQoEtKa03Yd75CfAPRbQex91b4CfdOr1+w9rMLIRTsQuSCgl2ITFCwC5EJCnYhMmGuanwBw/9OFFM4ExSOWGKquQdKNk1rbZcCCwRqPFHTQ4Wd2JnqDvB0V5bqCgDLQ1IUI0qBpQo792XprgVJYfVAYQfxTVPYE3yjghK0UAXxS2i9lKTGE9Ud4Ap7f4Wr8b2l+kn0lngerp1ZXm8o4p2lurILkQkKdiEyQcEuRCYo2IXIhLkKdCP0cHJ8wTpbipB2JhDS2BzRvKcapsACfD952r7z5imwLN012nfeVcXXgglvbD960Bu9R8ZH+86NtF9iqa7lHM1s5RzMt6PWSytk3zmxAUB/uX7CPWIDuBhnSyvU188srTeMJdAJkT0KdiEyQcEuRCa0af90v5n9t5k9V932dr5aIcTUtGn/BAB/7u4PbzBWCLEgNCk46QBY+6dkht7Ha6NfWGebRVrrEikS0VZhj3yZms5Ud4D3VOtKYR8l9FTzqOIrS3clKaxJfda44JxYkIKNj3ybKe9xumzdzlR3gCvvYQrsKlHjV/hJ2Ep9wb68TDyJva0aP9n+yd2frH71WTN73szuMzMeMUKIhWCq9k9m9m4Af4GyDdRvAtgF4BNs7Nr2T6feCF7mhRCdM237p5vd/VjV4XUVwD8gqCG/tv3ThbvmmsMjhFjDtO2ffmBml1c2Q9mu+VB3yxRCtKVN+6d/N7PLABiA5wD8ybkmGnof/zO8eJ2NiWsAF9iitNTlFF8mukWVWanARvaSF1wcSxHdmMDG9pcDwLioi1u0sisAMIEtarPUUIwLRbeGrZeiOdqmwEa+VLRLEOh6QZum3qBu7w0CgW6lfsK2GiiSq+QkBtx3PGH3oJ0a0K79043nGiuEWByUQSdEJijYhcgEBbsQmaBgFyIT5vrF93C8A0dX16vxUWVWpppHCvtgXFeiWbVWgKewRpVZB0Rlp/3QAjW+tcIeqOa0oAQZDwRqepDuSn2JuByPr9tYtddyjmY2ICg+EfVqGxI1vaGttBOFfRT51v84RmwAgBGxF9zXSYVYHwVfgYyD4xF0ZRciExTsQmSCgl2ITFCwC5EJcxXoBt7H0eWL1tuIuAZwgS0SwpjoNhzz1zGWrspENwAYFfU5CmaL9pKniG7MHlRxNWJnNoCLaRZoOqziKxsfCml0fOBLBbpICGPHCtJdqW/Csci8NuLpslaQOaL95MwetWryeE96G3RlFyITFOxCZIKCXYhMULALkQkKdiEyYb693sY9nFx5+zobU9IBrqZHavyQpaUGajxLYS2CVNMxOR5T2D1U2Mm84/YKO1PNQzWeKO+xck98WbpsSvGKyJeo3rFv83mZQk4VdqakA7Ax8SU2AAArFNGNkA4Y/5/V7BvUfdaVXYhMULALkQkKdiEyQcEuRCbYRtUoZ34ws58C+HH18FIAr8/t4PND57X12E7n9svufhn7xVyDfd2BzZ5x9+s25eAdovPaemznc1uL3sYLkQkKdiEyYTOD/YubeOwu0XltPbbzub3Fpn1mF0LMF72NFyIT5h7sZnazmf3QzF42s33zPv4sMbP9ZnbCzA6tse0ys4Nm9lL18+KN5lhEzGyPmT1hZi+a2Qtm9tHKvqXPzczON7OnzOx71Xl9prJfbWZPVs/JB82M1zff4sw12KtOsH8H4PcAXAvgDjO7dp5rmDH3A7h5wrYPwOPufg2Ax6vHW40RgI+7+7UA3gvgT6v/01Y/t1UAN7r7ewDsBXCzmb0XwF8DuM/dfxXAzwDctXlL7I55X9mvB/Cyu7/i7gMADwC4dc5rmBnu/i0Ab0yYbwVwoLp/AGXv+i2Fux9z92er+6cAHAZwBbb4uXnJ6erhzurmAG4E8HBl33Ln1ZR5B/sVAH6y5vGRyrad2O3ux6r7rwHYvZmLaYuZXYWyZfeT2AbnZmZ9M3sOwAkABwH8CMCb7n520+x2fE4CkEDXKV5+1bFlv+4ws3cA+BqAj7n7z9f+bquem7sX7r4XwJUo32m+a3NXND/mHexHAexZ8/jKyradOG5mlwNA9fPEJq9nKsxsJ8pA/4q7f70yb4tzAwB3fxPAEwDeB+AiMztbRWU7PicBzD/YnwZwTaV+ngfgwwAenfMauuZRAHdW9+8E8MgmrmUqzMwAfBnAYXf//JpfbelzM7PLzOyi6v4FAG5CqUc8AeBDlduWO6+mzD2pxsxuAfC3APoA9rv7Z+e6gBliZl8FcAPKXVPHAXwKwD8BeAjAL6Hc4Xe7u0+KeAuNmb0fwH8A+D7+v9DSJ1F+bt+y52Zmv45SgOujvNA95O5/aWa/glIs3gXguwD+0N1XN2+l3aAMOiEyQQKdEJmgYBciExTsQmSCgl2ITFCwC5EJCnYhMkHBLkQmKNiFyIT/A/QC68Xlf/pWAAAAAElFTkSuQmCC","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["polydata = np.load('./dataset/polydata.npy')\n","plt.imshow(polydata[0])"]},{"cell_type":"markdown","metadata":{"id":"dsTG_su8XDoj"},"source":["# Wasserstein Generative Adversarial Network with Keras\n","\n","The aim of this program is to implement a WGAN architecture and to test it on the Polynomial dataset.\n","\n","Code partially adapted on the new Polynomial dataset from the [GitHub Repository](https://github.com/eriklindernoren/Keras-GAN/blob/master/wgan/wgan.py)."]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":810,"status":"ok","timestamp":1633441560426,"user":{"displayName":"Lorenzo Valente","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTh0enxhVzBGrVgHIc03P7l-WgzoGzF2_H_aZg=s64","userId":"09158965273549322331"},"user_tz":-120},"id":"dn-3dHC4zfW0"},"outputs":[],"source":["class WGAN():\n","    def __init__(self, data):\n","\n","        self.x_train = data\n","        self.channels = 1\n","        self.img_shape =(self.x_train.shape[1], \n","                         self.x_train.shape[2], \n","                         self.channels)\n","        self.latent_dim = 2\n","        self.noise = Input(shape=(self.latent_dim,))\n","\n","        self.generator = None\n","        self.generator_model = None\n","\n","        self.critic = None\n","        self.critic_model = None\n","        self.n_critic = 5\n","        self.clip_value = 0.01\n","\n","        self.valid = None\n","        self.loss_record = np.array([None, None])\n","\n","    def wasserstein_loss(self, y_true, y_pred):\n","        return K.mean(y_true * y_pred)\n","    \n","    def build_generator_model(self):\n","\n","\n","        self.generator = Sequential(\n","            [\n","                self.noise,\n","                Dense(128 * 10 * 10, use_bias=False),\n","                BatchNormalization(momentum=0.8),\n","                LeakyReLU(alpha=0.2),\n","                Reshape((10, 10, 128)),\n","                UpSampling2D(),\n","\n","                Conv2DTranspose(128, kernel_size=3, padding='same', use_bias=False),\n","                BatchNormalization(momentum=0.8),\n","                LeakyReLU(alpha=0.2),\n","                UpSampling2D(),\n","        \n","                Conv2DTranspose(64, kernel_size=3, padding='same', use_bias=False),\n","                BatchNormalization(momentum=0.8),\n","                LeakyReLU(alpha=0.2),\n","\n","                Conv2DTranspose(self.channels, kernel_size=3, padding='same', use_bias=False),\n","                Activation(\"tanh\"),\n","            ],\n","            name=\"generator\",\n","        )\n","        self.generator.summary()\n","        self.generator_model = Model (self.noise, self.generator(self.noise) )\n","    \n","    def build_critic_model(self, optimizer = RMSprop(lr=0.00005)):\n","\n","        img_shape = Input(shape = self.img_shape)\n","\n","        x = 8\n","        self.critic = Sequential(\n","            [\n","                img_shape,\n","                Conv2D(x*16, kernel_size=3, strides=2, padding=\"same\"),\n","                LeakyReLU(alpha=0.2),\n","                Dropout(0.25),\n","\n","                Conv2D(x*32, kernel_size=3, strides=2, padding=\"same\"),\n","                ZeroPadding2D(padding=((0,1),(0,1))),\n","                BatchNormalization(momentum=0.8),\n","                LeakyReLU(alpha=0.2),\n","                Dropout(0.25),\n","\n","                Conv2D(x*64, kernel_size=3, strides=2, padding=\"same\"),\n","                BatchNormalization(momentum=0.8),\n","                LeakyReLU(alpha=0.2),\n","                Dropout(0.25),\n","\n","                Conv2D(x*128, kernel_size=3, strides=1, padding='same'),\n","                BatchNormalization(momentum=0.8),\n","                LeakyReLU(alpha=0.2),\n","                Dropout(0.25),\n","                Flatten(),\n","                Dense(self.channels),\n","                \n","            ],\n","            name=\"critic\"\n","        )\n","        self.critic.summary()\n","        self.critic_model = Model (img_shape, self.critic(img_shape) )\n","        self.critic_model.compile(loss=self.wasserstein_loss,\n","                                         optimizer = optimizer,\n","                                         metrics=['accuracy'])\n","        gen_imgs = self.generator_model(self.noise)\n","        self.critic_model.trainable = True\n","\n","\n","        self.valid = self.critic_model(gen_imgs)\n","        \n","    def combined_model(self, optimizer = RMSprop(lr=0.00005)):\n","            \n","        self.combined_model = Model (self.noise, self.valid)\n","        self.combined_model.compile(loss=self.wasserstein_loss,\n","                                       optimizer=optimizer)\n","\n","\n","    def train(self, epochs, batch_size=128, sample_interval=50):\n","\n","        \n","\n","        # Rescale -1 to 1\n","        self.x_train = np.expand_dims(self.x_train, axis=3)\n","\n","        # Adversarial ground truths\n","        valid = np.ones((batch_size, 1))\n","        fake = -np.ones((batch_size, 1))\n","\n","        for epoch in range(epochs):\n","            for _ in range(self.n_critic):\n","\n","                # +---------------------+\n","                # | Train Discriminator |\n","                # +---------------------+\n","\n","                # Select a random batch of images\n","                idx = np.random.randint(0, self.x_train.shape[0], batch_size)\n","                imgs = self.x_train[idx]\n","                \n","                # Sample noise as generator input\n","                noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n","\n","                # Generate a batch of new images\n","                gen_imgs = self.generator_model.predict(noise)\n","\n","                # Train the critic\n","                c_loss_real = self.critic_model.train_on_batch(imgs, valid)\n","                c_loss_fake = self.critic_model.train_on_batch(gen_imgs, fake)\n","                c_loss = 0.5 * np.add(c_loss_fake, c_loss_real)\n","\n","                # Clip critic weights\n","                for l in self.critic_model.layers:\n","                    weights = l.get_weights()\n","                    weights = [np.clip(w, -self.clip_value, self.clip_value) for w in weights]\n","                    l.set_weights(weights)\n","\n","\n","            # +------------------+\n","            # | Train Generator  |\n","            # +------------------+\n","\n","            #self.critic.trainable = False\n","            g_loss = self.combined_model.train_on_batch(noise, valid)\n","\n","            # Plot the progress\n","            #print(epoch)\n","            print (\"%d [C loss: %f] [G loss: %f]\" % (epoch+1, 1 - c_loss[0], 1 - g_loss))\n","            self.loss_record = np.vstack([self.loss_record, np.array([1- c_loss[0], 1- g_loss])])\n","\n","            # If at save interval => save generated image samples\n","            if epoch % sample_interval == 0:\n","                self.save_imgs(epoch)\n","\n","\n","    def save_imgs(self, epoch):\n","        r, c = 5, 5\n","        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n","        gen_imgs = self.generator.predict(noise)\n","\n","        # Rescale images 0 - 1\n","        gen_imgs = 0.5 * gen_imgs + 0.5\n","\n","        fig, axs = plt.subplots(r, c)\n","        cnt = 0\n","        for i in range(r):\n","            for j in range(c):\n","                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n","                axs[i,j].axis('off')\n","                cnt += 1\n","        fig.savefig(\"./images/WGAN/training_checkpoints/poly_%d.png\" % epoch)\n","        plt.close()\n","\n","    def fig(self):\n","        fig, axes = plt.subplots(2, 8, figsize=(19,5))\n","        for i in range(2):\n","            for j in range(8):\n","                out = self.generator_model.predict(np.reshape(np.random.normal(0,1,2),(1,2)))\n","                axes[i,j].imshow(out[0,:,:,0])\n","        fig.savefig(\"./images/WGAN/generated.png\")\n","\n","        fig, axes = plt.subplots(2, 8, figsize=(19,5))\n","        for i in range(2):\n","            for j in range(8):\n","                axes[i,j].imshow(polydata[i*j+j])\n","        fig.savefig(\"./images/WGAN/original.png\")\n","\n","    def gif(self):\n","        \"\"\"Creation of the gif with generated images over epochs.\"\"\"\n","\n","        with imageio.get_writer('./images/WGAN/wgan_poly.gif', mode='I') as writer:\n","            filenames = glob.glob('./images/WGAN/training_checkpoints/poly*.png')\n","            filenames = sorted(filenames)\n","            for filename in filenames:\n","                image = imageio.imread(filename)\n","                writer.append_data(image)\n","            image = imageio.imread(filename)\n","            writer.append_data(image)\n","            embed.embed_file('./images/WGAN/wgan_poly.gif')\n","\n","    def plot_losses(self):\n","        #Plotting the Generator and Discriminator losses\n","        fig = plt.figure(figsize=(5, 5))\n","        plt.plot(self.loss_record[:])\n","        plt.ylabel('Loss')\n","        plt.xlabel('Epoch')\n","        plt.legend(['Generator Loss', 'critic Loss'], loc='best')\n","        plt.title('Generator and Critic losses')\n","        plt.savefig('./images/WGAN/g_c_losses.png')\n","\n","        plt.show()\n","\n","    def dir(self):\n","        \"\"\"Creation of the folders path to store the results.\"\"\"\n","        dir = os.path.join(\"images\")\n","        if not os.path.exists(dir):\n","            os.mkdir(dir)\n","        dir2 = os.path.join(\"./images/WGAN\")\n","        if not os.path.exists(dir2):\n","            os.mkdir(dir2)\n","        dir3 = os.path.join(\"./images/WGAN/training_checkpoints\")\n","        if not os.path.exists(dir3):\n","            os.mkdir(dir3)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"generator\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_8 (Dense)              (None, 12800)             25600     \n","_________________________________________________________________\n","batch_normalization_24 (Batc (None, 12800)             51200     \n","_________________________________________________________________\n","leaky_re_lu_28 (LeakyReLU)   (None, 12800)             0         \n","_________________________________________________________________\n","reshape_4 (Reshape)          (None, 10, 10, 128)       0         \n","_________________________________________________________________\n","up_sampling2d_8 (UpSampling2 (None, 20, 20, 128)       0         \n","_________________________________________________________________\n","conv2d_transpose_12 (Conv2DT (None, 20, 20, 128)       147456    \n","_________________________________________________________________\n","batch_normalization_25 (Batc (None, 20, 20, 128)       512       \n","_________________________________________________________________\n","leaky_re_lu_29 (LeakyReLU)   (None, 20, 20, 128)       0         \n","_________________________________________________________________\n","up_sampling2d_9 (UpSampling2 (None, 40, 40, 128)       0         \n","_________________________________________________________________\n","conv2d_transpose_13 (Conv2DT (None, 40, 40, 64)        73728     \n","_________________________________________________________________\n","batch_normalization_26 (Batc (None, 40, 40, 64)        256       \n","_________________________________________________________________\n","leaky_re_lu_30 (LeakyReLU)   (None, 40, 40, 64)        0         \n","_________________________________________________________________\n","conv2d_transpose_14 (Conv2DT (None, 40, 40, 1)         576       \n","_________________________________________________________________\n","activation_4 (Activation)    (None, 40, 40, 1)         0         \n","=================================================================\n","Total params: 299,328\n","Trainable params: 273,344\n","Non-trainable params: 25,984\n","_________________________________________________________________\n","Model: \"critic\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_16 (Conv2D)           (None, 20, 20, 128)       1280      \n","_________________________________________________________________\n","leaky_re_lu_31 (LeakyReLU)   (None, 20, 20, 128)       0         \n","_________________________________________________________________\n","dropout_16 (Dropout)         (None, 20, 20, 128)       0         \n","_________________________________________________________________\n","conv2d_17 (Conv2D)           (None, 10, 10, 256)       295168    \n","_________________________________________________________________\n","zero_padding2d_4 (ZeroPaddin (None, 11, 11, 256)       0         \n","_________________________________________________________________\n","batch_normalization_27 (Batc (None, 11, 11, 256)       1024      \n","_________________________________________________________________\n","leaky_re_lu_32 (LeakyReLU)   (None, 11, 11, 256)       0         \n","_________________________________________________________________\n","dropout_17 (Dropout)         (None, 11, 11, 256)       0         \n","_________________________________________________________________\n","conv2d_18 (Conv2D)           (None, 6, 6, 512)         1180160   \n","_________________________________________________________________\n","batch_normalization_28 (Batc (None, 6, 6, 512)         2048      \n","_________________________________________________________________\n","leaky_re_lu_33 (LeakyReLU)   (None, 6, 6, 512)         0         \n","_________________________________________________________________\n","dropout_18 (Dropout)         (None, 6, 6, 512)         0         \n","_________________________________________________________________\n","conv2d_19 (Conv2D)           (None, 6, 6, 1024)        4719616   \n","_________________________________________________________________\n","batch_normalization_29 (Batc (None, 6, 6, 1024)        4096      \n","_________________________________________________________________\n","leaky_re_lu_34 (LeakyReLU)   (None, 6, 6, 1024)        0         \n","_________________________________________________________________\n","dropout_19 (Dropout)         (None, 6, 6, 1024)        0         \n","_________________________________________________________________\n","flatten_4 (Flatten)          (None, 36864)             0         \n","_________________________________________________________________\n","dense_9 (Dense)              (None, 1)                 36865     \n","=================================================================\n","Total params: 6,240,257\n","Trainable params: 6,236,673\n","Non-trainable params: 3,584\n","_________________________________________________________________\n","1 [D loss: 0.999300] [G loss: 1.001482]\n","2 [D loss: 0.999296] [G loss: 1.005983]\n","3 [D loss: 0.999230] [G loss: 1.010404]\n","4 [D loss: 0.999149] [G loss: 1.014975]\n","5 [D loss: 0.999039] [G loss: 1.019675]\n","6 [D loss: 0.998921] [G loss: 1.024581]\n","7 [D loss: 0.998742] [G loss: 1.029531]\n","8 [D loss: 0.998568] [G loss: 1.034547]\n","9 [D loss: 0.998409] [G loss: 1.039600]\n","10 [D loss: 0.998193] [G loss: 1.044675]\n","11 [D loss: 0.997981] [G loss: 1.049667]\n","12 [D loss: 0.997885] [G loss: 1.054554]\n","13 [D loss: 0.997873] [G loss: 1.059561]\n","14 [D loss: 0.997692] [G loss: 1.064742]\n","15 [D loss: 0.997650] [G loss: 1.069826]\n","16 [D loss: 0.997883] [G loss: 1.075064]\n","17 [D loss: 0.998141] [G loss: 1.080392]\n","18 [D loss: 0.999180] [G loss: 1.086581]\n","19 [D loss: 1.001009] [G loss: 1.095141]\n","20 [D loss: 1.003267] [G loss: 1.105428]\n","21 [D loss: 1.006494] [G loss: 1.117580]\n","22 [D loss: 1.011379] [G loss: 1.130331]\n","23 [D loss: 1.012966] [G loss: 1.140272]\n","24 [D loss: 1.022741] [G loss: 1.145230]\n","25 [D loss: 1.038614] [G loss: 1.148858]\n","26 [D loss: 1.050548] [G loss: 1.167414]\n","27 [D loss: 1.055076] [G loss: 1.165811]\n","28 [D loss: 1.081472] [G loss: 1.172334]\n","29 [D loss: 1.099202] [G loss: 1.170878]\n","30 [D loss: 1.127070] [G loss: 1.177296]\n","31 [D loss: 1.143112] [G loss: 1.185472]\n","32 [D loss: 1.178090] [G loss: 1.190364]\n","33 [D loss: 1.186473] [G loss: 1.214022]\n","34 [D loss: 1.254772] [G loss: 1.212764]\n","35 [D loss: 1.229236] [G loss: 1.228084]\n","36 [D loss: 1.309326] [G loss: 1.234233]\n","37 [D loss: 1.358042] [G loss: 1.291894]\n","38 [D loss: 1.444025] [G loss: 1.260682]\n","39 [D loss: 1.478037] [G loss: 1.366377]\n","40 [D loss: 1.542013] [G loss: 1.437263]\n","41 [D loss: 1.681455] [G loss: 1.590678]\n","42 [D loss: 1.794185] [G loss: 1.770687]\n","43 [D loss: 1.857520] [G loss: 1.839117]\n","44 [D loss: 1.428233] [G loss: 1.843126]\n","45 [D loss: 1.711502] [G loss: 1.921227]\n","46 [D loss: 1.340385] [G loss: 1.820281]\n","47 [D loss: 1.579464] [G loss: 1.890900]\n","48 [D loss: 1.317941] [G loss: 1.891370]\n","49 [D loss: 1.436404] [G loss: 1.745329]\n","50 [D loss: 1.174238] [G loss: 1.773060]\n","51 [D loss: 1.232882] [G loss: 1.672975]\n","52 [D loss: 1.269250] [G loss: 1.531234]\n","53 [D loss: 1.312634] [G loss: 1.427963]\n","54 [D loss: 1.365817] [G loss: 1.267867]\n","55 [D loss: 1.406804] [G loss: 1.210104]\n","56 [D loss: 1.456198] [G loss: 1.065272]\n","57 [D loss: 1.492246] [G loss: 0.982847]\n","58 [D loss: 1.526291] [G loss: 0.939044]\n","59 [D loss: 1.568448] [G loss: 0.823284]\n","60 [D loss: 1.590528] [G loss: 0.799916]\n","61 [D loss: 1.644179] [G loss: 0.730942]\n","62 [D loss: 1.645848] [G loss: 0.741247]\n","63 [D loss: 1.675936] [G loss: 0.729044]\n","64 [D loss: 1.674886] [G loss: 0.732095]\n","65 [D loss: 1.691858] [G loss: 0.701530]\n","66 [D loss: 1.687177] [G loss: 0.694584]\n","67 [D loss: 1.704415] [G loss: 0.711322]\n","68 [D loss: 1.716419] [G loss: 0.716362]\n","69 [D loss: 1.712993] [G loss: 0.766999]\n","70 [D loss: 1.708904] [G loss: 0.783844]\n","71 [D loss: 1.742037] [G loss: 0.738960]\n","72 [D loss: 1.726262] [G loss: 0.832011]\n","73 [D loss: 1.672535] [G loss: 0.961467]\n","74 [D loss: 1.638502] [G loss: 0.999194]\n","75 [D loss: 1.686574] [G loss: 0.954734]\n","76 [D loss: 1.604667] [G loss: 1.063059]\n","77 [D loss: 1.625041] [G loss: 0.945925]\n","78 [D loss: 1.649342] [G loss: 0.957867]\n","79 [D loss: 1.667680] [G loss: 0.970310]\n","80 [D loss: 1.652370] [G loss: 0.936472]\n","81 [D loss: 1.682222] [G loss: 0.915034]\n","82 [D loss: 1.725981] [G loss: 0.859832]\n","83 [D loss: 1.761960] [G loss: 0.825303]\n","84 [D loss: 1.787418] [G loss: 0.749939]\n","85 [D loss: 1.815033] [G loss: 0.714310]\n","86 [D loss: 1.862295] [G loss: 0.677945]\n","87 [D loss: 1.872303] [G loss: 0.617673]\n","88 [D loss: 1.923683] [G loss: 0.649659]\n","89 [D loss: 1.926982] [G loss: 0.645748]\n","90 [D loss: 1.932964] [G loss: 0.582496]\n","91 [D loss: 1.944744] [G loss: 0.633175]\n","92 [D loss: 1.962660] [G loss: 0.634041]\n","93 [D loss: 1.955320] [G loss: 0.733568]\n","94 [D loss: 1.935034] [G loss: 0.793492]\n","95 [D loss: 1.897750] [G loss: 0.863776]\n","96 [D loss: 1.892274] [G loss: 0.930211]\n","97 [D loss: 1.832512] [G loss: 0.975376]\n","98 [D loss: 1.807246] [G loss: 1.046454]\n","99 [D loss: 1.791671] [G loss: 1.116798]\n","100 [D loss: 1.780335] [G loss: 1.147280]\n","101 [D loss: 1.742663] [G loss: 1.223816]\n","102 [D loss: 1.772180] [G loss: 1.239198]\n","103 [D loss: 1.781007] [G loss: 1.252626]\n","104 [D loss: 1.723109] [G loss: 1.198465]\n","105 [D loss: 1.757482] [G loss: 1.254219]\n","106 [D loss: 1.764035] [G loss: 1.164756]\n","107 [D loss: 1.745461] [G loss: 1.104772]\n","108 [D loss: 1.767079] [G loss: 1.035208]\n","109 [D loss: 1.812360] [G loss: 1.101188]\n","110 [D loss: 1.832033] [G loss: 1.120508]\n","111 [D loss: 1.834081] [G loss: 1.088004]\n","112 [D loss: 1.861532] [G loss: 1.042045]\n","113 [D loss: 1.833861] [G loss: 1.000735]\n","114 [D loss: 1.848282] [G loss: 0.954723]\n","115 [D loss: 1.910766] [G loss: 0.928850]\n","116 [D loss: 1.873230] [G loss: 0.886342]\n","117 [D loss: 1.915886] [G loss: 0.903739]\n","118 [D loss: 1.920205] [G loss: 0.828405]\n","119 [D loss: 1.886238] [G loss: 0.902758]\n","120 [D loss: 1.942538] [G loss: 0.829661]\n","121 [D loss: 1.955298] [G loss: 0.872053]\n","122 [D loss: 1.970661] [G loss: 0.878318]\n","123 [D loss: 1.984817] [G loss: 0.919361]\n","124 [D loss: 1.938127] [G loss: 0.874114]\n","125 [D loss: 1.975627] [G loss: 0.946289]\n","126 [D loss: 1.919811] [G loss: 0.946408]\n","127 [D loss: 1.912351] [G loss: 0.906108]\n","128 [D loss: 1.942158] [G loss: 0.917665]\n","129 [D loss: 1.894910] [G loss: 0.929086]\n","130 [D loss: 1.905659] [G loss: 1.022553]\n","131 [D loss: 1.886849] [G loss: 0.994817]\n","132 [D loss: 1.871224] [G loss: 1.032127]\n","133 [D loss: 1.907211] [G loss: 1.002829]\n","134 [D loss: 1.833240] [G loss: 1.099226]\n","135 [D loss: 1.890329] [G loss: 1.080911]\n","136 [D loss: 1.820771] [G loss: 1.081555]\n","137 [D loss: 1.866732] [G loss: 1.123493]\n","138 [D loss: 1.864195] [G loss: 1.115797]\n","139 [D loss: 1.855330] [G loss: 1.149640]\n","140 [D loss: 1.867942] [G loss: 1.141767]\n","141 [D loss: 1.854407] [G loss: 1.101328]\n","142 [D loss: 1.860742] [G loss: 1.137983]\n","143 [D loss: 1.821638] [G loss: 1.142356]\n","144 [D loss: 1.794732] [G loss: 1.142927]\n","145 [D loss: 1.786429] [G loss: 1.153764]\n","146 [D loss: 1.796882] [G loss: 1.143236]\n","147 [D loss: 1.791449] [G loss: 1.119678]\n","148 [D loss: 1.767729] [G loss: 1.171842]\n","149 [D loss: 1.745030] [G loss: 1.149979]\n","150 [D loss: 1.813138] [G loss: 1.163894]\n","151 [D loss: 1.789284] [G loss: 1.240504]\n","152 [D loss: 1.743732] [G loss: 1.177848]\n","153 [D loss: 1.779718] [G loss: 1.181815]\n","154 [D loss: 1.753365] [G loss: 1.181469]\n","155 [D loss: 1.715362] [G loss: 1.174608]\n","156 [D loss: 1.769326] [G loss: 1.197441]\n","157 [D loss: 1.768309] [G loss: 1.236457]\n","158 [D loss: 1.767697] [G loss: 1.228945]\n","159 [D loss: 1.750059] [G loss: 1.231027]\n","160 [D loss: 1.721139] [G loss: 1.221580]\n","161 [D loss: 1.695699] [G loss: 1.225986]\n","162 [D loss: 1.662815] [G loss: 1.287681]\n","163 [D loss: 1.693444] [G loss: 1.266432]\n","164 [D loss: 1.715101] [G loss: 1.303580]\n","165 [D loss: 1.696074] [G loss: 1.303394]\n","166 [D loss: 1.694245] [G loss: 1.283237]\n","167 [D loss: 1.679697] [G loss: 1.312038]\n","168 [D loss: 1.626761] [G loss: 1.355675]\n","169 [D loss: 1.706346] [G loss: 1.381825]\n","170 [D loss: 1.639893] [G loss: 1.339953]\n","171 [D loss: 1.603413] [G loss: 1.347309]\n","172 [D loss: 1.642309] [G loss: 1.366093]\n"]}],"source":["wgan=WGAN(polydata)\n","wgan.build_generator_model()\n","wgan.build_critic_model()\n","wgan.combined_model()\n","wgan.dir()\n","wgan.train(epochs=1000, sample_interval=50)\n","wgan.fig()\n","wgan.plot_losses()\n","wgan.gif()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Copia di GAN4.ipynb","provenance":[{"file_id":"1nIiHLgYl53OZWhgPmQxm09avXVAOJd5b","timestamp":1633442598877}]},"interpreter":{"hash":"789093bb736187c46b4a361b2c83e244a48ff9bb7ad40e66e5ffb40455c8edff"},"kernelspec":{"display_name":"Python 3.8.8 64-bit ('MLinPhysics': conda)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":2}
