{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":301,"status":"ok","timestamp":1633441509360,"user":{"displayName":"Lorenzo Valente","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTh0enxhVzBGrVgHIc03P7l-WgzoGzF2_H_aZg=s64","userId":"09158965273549322331"},"user_tz":-120},"id":"3HYjFWp2EZ-o"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow.python.keras import Input, Sequential\n","from tensorflow.python.keras.engine.functional import Functional\n","from tensorflow.python.keras.engine.keras_tensor import KerasTensor\n","from tensorflow.python.keras.models import Model\n","\n","gpus = tf.config.experimental.list_physical_devices('GPU')\n","if gpus:\n","    try:\n","        # Currently, memory growth needs to be the same across GPUs\n","        for gpu in gpus:\n","            tf.config.experimental.set_memory_growth(gpu, True)\n","        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n","        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n","    except RuntimeError as e:\n","        # Memory growth must be set before GPUs have been initialized\n","        print(e)\n","\n","from tensorflow.keras.layers import (Dense, Lambda, Conv2D, Conv2DTranspose, LeakyReLU, \n","                                    BatchNormalization,UpSampling2D, ZeroPadding2D, Activation ,Flatten, Reshape, Cropping2D, Dropout)\n","from tensorflow.python.keras.utils.np_utils import to_categorical\n","from tensorflow.keras.constraints import MinMaxNorm\n","\n","from tensorflow.keras import backend as K\n","\n","import glob\n","import imageio\n","import os\n","import PIL\n","import time\n","\n","from IPython import display\n","from tensorflow.keras.optimizers import Adam, RMSprop\n","\n","import tensorflow_docs.vis.embed as embed"]},{"cell_type":"markdown","metadata":{"id":"JnawiBWUs_5V"},"source":["## Loading the Polynomial dataset"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/plain":["<matplotlib.image.AxesImage at 0x29efe05c490>"]},"execution_count":4,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["polydata = np.load('./dataset/polydata.npy')\n","plt.imshow(polydata[0])"]},{"cell_type":"markdown","metadata":{"id":"dsTG_su8XDoj"},"source":["# Wasserstein Generative Adversarial Network with Keras\n","\n","The aim of this program is to implement a WGAN architecture and to test it on the Polynomial dataset.\n","\n","Code partially adapted on the new Polynomial dataset from the [GitHub Repository](https://github.com/eriklindernoren/Keras-GAN/blob/master/wgan/wgan.py)."]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":810,"status":"ok","timestamp":1633441560426,"user":{"displayName":"Lorenzo Valente","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTh0enxhVzBGrVgHIc03P7l-WgzoGzF2_H_aZg=s64","userId":"09158965273549322331"},"user_tz":-120},"id":"dn-3dHC4zfW0"},"outputs":[],"source":["class WGAN():\n","    def __init__(self, data):\n","\n","        self.x_train = data\n","        self.channels = 1\n","        self.img_shape =(self.x_train.shape[1], \n","                         self.x_train.shape[2], \n","                         self.channels)\n","        self.latent_dim = 2\n","        self.noise = Input(shape=(self.latent_dim,))\n","\n","        self.generator = None\n","        self.generator_model = None\n","\n","        self.critic = None\n","        self.critic_model = None\n","        self.n_critic = 5\n","        self.clip_value = 0.03\n","\n","        self.valid = None\n","        self.loss_record = np.array([None, None])\n","\n","    def wasserstein_loss(self, y_true, y_pred):\n","        return K.mean(y_true * y_pred)\n","    \n","    def build_generator_model(self):\n","\n","\n","        self.generator = Sequential(\n","            [\n","                self.noise,\n","                Dense(128 * 10 * 10, use_bias=False),\n","                BatchNormalization(momentum=0.8),\n","                LeakyReLU(alpha=0.2),\n","                Reshape((10, 10, 128)),\n","                UpSampling2D(),\n","\n","                Conv2DTranspose(128, kernel_size=3, padding='same', use_bias=False),\n","                #BatchNormalization(momentum=0.8),\n","                LeakyReLU(alpha=0.2),\n","                UpSampling2D(),\n","        \n","                Conv2DTranspose(64, kernel_size=3, padding='same', use_bias=False),\n","                #BatchNormalization(momentum=0.8),\n","                LeakyReLU(alpha=0.2),\n","\n","                Conv2DTranspose(self.channels, kernel_size=3, padding='same', use_bias=False),\n","                Activation(\"tanh\"),\n","            ],\n","            name=\"generator\",\n","        )\n","        self.generator.summary()\n","        self.generator_model = Model (self.noise, self.generator(self.noise) )\n","    \n","    def build_critic_model(self, optimizer = RMSprop(lr=0.00003)):\n","\n","        img_shape = Input(shape = self.img_shape)\n","\n","        x = 8\n","        self.critic = Sequential(\n","            [\n","                img_shape,\n","                Conv2D(x*16, kernel_size=3, strides=2, padding=\"same\"),\n","                LeakyReLU(alpha=0.2),\n","                Dropout(0.25),\n","\n","                Conv2D(x*32, kernel_size=3, strides=2, padding=\"same\"),\n","                ZeroPadding2D(padding=((0,1),(0,1))),\n","                BatchNormalization(momentum=0.8),\n","                LeakyReLU(alpha=0.2),\n","                Dropout(0.25),\n","\n","                Conv2D(x*64, kernel_size=3, strides=2, padding=\"same\"),\n","                BatchNormalization(momentum=0.8),\n","                LeakyReLU(alpha=0.2),\n","                Dropout(0.25),\n","\n","                Conv2D(x*128, kernel_size=3, strides=1, padding='same'),\n","                BatchNormalization(momentum=0.8),\n","                LeakyReLU(alpha=0.2),\n","                Dropout(0.25),\n","                Flatten(),\n","                Dense(self.channels),\n","                \n","            ],\n","            name=\"critic\"\n","        )\n","        self.critic.summary()\n","        self.critic_model = Model (img_shape, self.critic(img_shape) )\n","        self.critic_model.compile(loss=self.wasserstein_loss,\n","                                         optimizer = optimizer,\n","                                         metrics=['accuracy'])\n","        gen_imgs = self.generator_model(self.noise)\n","        self.critic_model.trainable = True\n","\n","\n","        self.valid = self.critic_model(gen_imgs)\n","        \n","    def combined_model(self, optimizer = RMSprop(lr=0.00003)):\n","            \n","        self.combined_model = Model (self.noise, self.valid)\n","        self.combined_model.compile(loss=self.wasserstein_loss,\n","                                       optimizer=optimizer)\n","\n","\n","    def train(self, epochs, batch_size=128, sample_interval=50):\n","\n","        \n","\n","        # Rescale -1 to 1\n","        self.x_train = np.expand_dims(self.x_train, axis=3)\n","\n","        # Adversarial ground truths\n","        valid = np.ones((batch_size, 1))\n","        fake = -np.ones((batch_size, 1))\n","\n","        for epoch in range(epochs):\n","            for _ in range(self.n_critic):\n","\n","                # ---------------------\n","                #  Train Discriminator\n","                # ---------------------\n","\n","                # Select a random batch of images\n","                idx = np.random.randint(0, self.x_train.shape[0], batch_size)\n","                imgs = self.x_train[idx]\n","                \n","                # Sample noise as generator input\n","                noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n","\n","                # Generate a batch of new images\n","                gen_imgs = self.generator_model.predict(noise)\n","\n","                # Train the critic\n","                c_loss_real = self.critic_model.train_on_batch(imgs, valid)\n","                c_loss_fake = self.critic_model.train_on_batch(gen_imgs, fake)\n","                c_loss = 0.5 * np.add(c_loss_fake, c_loss_real)\n","\n","                # Clip critic weights\n","                for l in self.critic_model.layers:\n","                    weights = l.get_weights()\n","                    weights = [np.clip(w, -self.clip_value, self.clip_value) for w in weights]\n","                    l.set_weights(weights)\n","\n","\n","            # ---------------------\n","            #  Train Generator\n","            # ---------------------\n","\n","            #self.critic.trainable = False\n","            g_loss = self.combined_model.train_on_batch(noise, valid)\n","\n","            # Plot the progress\n","            #print(epoch)\n","            print (\"%d [D loss: %f] [G loss: %f]\" % (epoch+1, 1 - c_loss[0], 1 - g_loss))\n","            self.loss_record = np.vstack([self.loss_record, np.array([1- c_loss[0], 1- g_loss])])\n","\n","            # If at save interval => save generated image samples\n","            #if epoch % sample_interval == 0:\n","             #   self.save_imgs(epoch)\n","\n","\n","    def save_imgs(self, epoch):\n","        r, c = 5, 5\n","        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n","        gen_imgs = self.generator.predict(noise)\n","\n","        # Rescale images 0 - 1\n","        gen_imgs = 0.5 * gen_imgs + 0.5\n","\n","        fig, axs = plt.subplots(r, c)\n","        cnt = 0\n","        for i in range(r):\n","            for j in range(c):\n","                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n","                axs[i,j].axis('off')\n","                cnt += 1\n","        fig.savefig(\"images/poly_%d.png\" % epoch)\n","        plt.close()\n","\n","    def fig(self):\n","        fig, axes = plt.subplots(2, 8, figsize=(19,5))\n","        for i in range(2):\n","            for j in range(8):\n","                out = self.generator_model.predict(np.reshape(np.random.normal(0,1,2),(1,2)))\n","                axes[i,j].imshow(out[0,:,:,0])\n","    \n","        fig, axes = plt.subplots(2, 8, figsize=(19,5))\n","        for i in range(2):\n","            for j in range(8):\n","                axes[i,j].imshow(polydata[i*j+j])\n","    \n","    def plot_losses(self):\n","        #Plotting the Generator and Discriminator losses\n","        fig = plt.figure(figsize=(5, 5))\n","        #plt.subplot(5)\n","        plt.plot(self.loss_record[:])\n","        plt.ylabel('Loss')\n","        plt.xlabel('Epoch')\n","        plt.legend(['Generator Loss', 'critic Loss'], loc='best')\n","        plt.title('Generator and Critic losses')\n","        #plt.savefig('./images/GAN/g_c_losses.png')\n","\n","        plt.show()"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"generator\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_4 (Dense)              (None, 12800)             25600     \n","_________________________________________________________________\n","batch_normalization_8 (Batch (None, 12800)             51200     \n","_________________________________________________________________\n","leaky_re_lu_14 (LeakyReLU)   (None, 12800)             0         \n","_________________________________________________________________\n","reshape_2 (Reshape)          (None, 10, 10, 128)       0         \n","_________________________________________________________________\n","up_sampling2d_4 (UpSampling2 (None, 20, 20, 128)       0         \n","_________________________________________________________________\n","conv2d_transpose_6 (Conv2DTr (None, 20, 20, 128)       147456    \n","_________________________________________________________________\n","leaky_re_lu_15 (LeakyReLU)   (None, 20, 20, 128)       0         \n","_________________________________________________________________\n","up_sampling2d_5 (UpSampling2 (None, 40, 40, 128)       0         \n","_________________________________________________________________\n","conv2d_transpose_7 (Conv2DTr (None, 40, 40, 64)        73728     \n","_________________________________________________________________\n","leaky_re_lu_16 (LeakyReLU)   (None, 40, 40, 64)        0         \n","_________________________________________________________________\n","conv2d_transpose_8 (Conv2DTr (None, 40, 40, 1)         576       \n","_________________________________________________________________\n","activation_2 (Activation)    (None, 40, 40, 1)         0         \n","=================================================================\n","Total params: 298,560\n","Trainable params: 272,960\n","Non-trainable params: 25,600\n","_________________________________________________________________\n","Model: \"critic\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_8 (Conv2D)            (None, 20, 20, 128)       1280      \n","_________________________________________________________________\n","leaky_re_lu_17 (LeakyReLU)   (None, 20, 20, 128)       0         \n","_________________________________________________________________\n","dropout_8 (Dropout)          (None, 20, 20, 128)       0         \n","_________________________________________________________________\n","conv2d_9 (Conv2D)            (None, 10, 10, 256)       295168    \n","_________________________________________________________________\n","zero_padding2d_2 (ZeroPaddin (None, 11, 11, 256)       0         \n","_________________________________________________________________\n","batch_normalization_9 (Batch (None, 11, 11, 256)       1024      \n","_________________________________________________________________\n","leaky_re_lu_18 (LeakyReLU)   (None, 11, 11, 256)       0         \n","_________________________________________________________________\n","dropout_9 (Dropout)          (None, 11, 11, 256)       0         \n","_________________________________________________________________\n","conv2d_10 (Conv2D)           (None, 6, 6, 512)         1180160   \n","_________________________________________________________________\n","batch_normalization_10 (Batc (None, 6, 6, 512)         2048      \n","_________________________________________________________________\n","leaky_re_lu_19 (LeakyReLU)   (None, 6, 6, 512)         0         \n","_________________________________________________________________\n","dropout_10 (Dropout)         (None, 6, 6, 512)         0         \n","_________________________________________________________________\n","conv2d_11 (Conv2D)           (None, 6, 6, 1024)        4719616   \n","_________________________________________________________________\n","batch_normalization_11 (Batc (None, 6, 6, 1024)        4096      \n","_________________________________________________________________\n","leaky_re_lu_20 (LeakyReLU)   (None, 6, 6, 1024)        0         \n","_________________________________________________________________\n","dropout_11 (Dropout)         (None, 6, 6, 1024)        0         \n","_________________________________________________________________\n","flatten_2 (Flatten)          (None, 36864)             0         \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 1)                 36865     \n","=================================================================\n","Total params: 6,240,257\n","Trainable params: 6,236,673\n","Non-trainable params: 3,584\n","_________________________________________________________________\n"]}],"source":["gan=WGAN(polydata)\n","gan.build_generator_model()\n","gan.build_critic_model()\n","gan.combined_model()\n","gan.train(epochs=5)\n","gan.fig()\n","gan.plot_losses()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Copia di GAN4.ipynb","provenance":[{"file_id":"1nIiHLgYl53OZWhgPmQxm09avXVAOJd5b","timestamp":1633442598877}]},"interpreter":{"hash":"789093bb736187c46b4a361b2c83e244a48ff9bb7ad40e66e5ffb40455c8edff"},"kernelspec":{"display_name":"Python 3.8.8 64-bit ('MLinPhysics': conda)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":2}
